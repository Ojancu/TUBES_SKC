{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10306644,"sourceType":"datasetVersion","datasetId":6380057}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Necessary Library ","metadata":{}},{"cell_type":"code","source":"# importing libraries\nimport pandas as pd\nimport scipy\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pickle\n\nfrom os import path\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:15.706786Z","iopub.execute_input":"2025-01-02T23:03:15.707153Z","iopub.status.idle":"2025-01-02T23:03:17.636018Z","shell.execute_reply.started":"2025-01-02T23:03:15.707104Z","shell.execute_reply":"2025-01-02T23:03:17.635093Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Import Dataset","metadata":{}},{"cell_type":"code","source":"df_raw = pd.read_csv(\"/kaggle/input/mitm-attack/MitM.csv\", low_memory= False)\ndf_raw.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:17.637394Z","iopub.execute_input":"2025-01-02T23:03:17.637886Z","iopub.status.idle":"2025-01-02T23:03:18.569634Z","shell.execute_reply.started":"2025-01-02T23:03:17.637856Z","shell.execute_reply":"2025-01-02T23:03:18.564462Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5573017537a8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/mitm-attack/MitM.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._maybe_upcast\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36mputmask\u001b[0;34m(a, mask, values)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_from_c_func_and_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \"\"\"\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"df_raw.shape","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.570195Z","iopub.status.idle":"2025-01-02T23:03:18.570516Z","shell.execute_reply":"2025-01-02T23:03:18.570393Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_raw.info()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.571263Z","iopub.status.idle":"2025-01-02T23:03:18.571555Z","shell.execute_reply":"2025-01-02T23:03:18.571438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_raw.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.572093Z","iopub.status.idle":"2025-01-02T23:03:18.572391Z","shell.execute_reply":"2025-01-02T23:03:18.572278Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_raw.describe()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.573037Z","iopub.status.idle":"2025-01-02T23:03:18.573431Z","shell.execute_reply":"2025-01-02T23:03:18.573263Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_raw['type'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:03:18.574058Z","iopub.status.idle":"2025-01-02T23:03:18.574396Z","shell.execute_reply":"2025-01-02T23:03:18.574274Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop columns with too many missing values (e.g., 50% or more)\nthreshold = 0.5\ndf = df_raw.copy()\ndf = df.loc[:, df.isnull().mean() < threshold]\n\n# Impute remaining null values using median for numerical columns\nnum_cols = df.select_dtypes(include=[np.number]).columns\nimputer = SimpleImputer(strategy='median')\ndf[num_cols] = imputer.fit_transform(df[num_cols])\n\n# Forward fill for categorical columns (if applicable)\ncat_cols = df.select_dtypes(include=[object]).columns\ndf[cat_cols] = df[cat_cols].ffill()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.575246Z","iopub.status.idle":"2025-01-02T23:03:18.575555Z","shell.execute_reply":"2025-01-02T23:03:18.575411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['type'] = df['type'].map({'normal': 1, 'mitm': 0})","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.576422Z","iopub.status.idle":"2025-01-02T23:03:18.576707Z","shell.execute_reply":"2025-01-02T23:03:18.576597Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.577642Z","iopub.status.idle":"2025-01-02T23:03:18.578016Z","shell.execute_reply":"2025-01-02T23:03:18.577883Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.579036Z","iopub.status.idle":"2025-01-02T23:03:18.579435Z","shell.execute_reply":"2025-01-02T23:03:18.579281Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select only numeric columns for correlation analysis\nnumeric_df = df.copy()\nnum_col = numeric_df.select_dtypes(include=[np.number]).columns\ndata_num = df[num_col].copy()\ndata_num.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.580225Z","iopub.status.idle":"2025-01-02T23:03:18.580548Z","shell.execute_reply":"2025-01-02T23:03:18.580425Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_num.shape","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.581466Z","iopub.status.idle":"2025-01-02T23:03:18.581772Z","shell.execute_reply":"2025-01-02T23:03:18.581652Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_col = df.columns.difference(num_col)\ncat_col = cat_col[1:]\ncat_col","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.582691Z","iopub.status.idle":"2025-01-02T23:03:18.583031Z","shell.execute_reply":"2025-01-02T23:03:18.582907Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creating a dataframe with only categorical attributes\ndata_cat = df_raw[cat_col].copy()\ndata_cat.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.583824Z","iopub.status.idle":"2025-01-02T23:03:18.584270Z","shell.execute_reply":"2025-01-02T23:03:18.584084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_num","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.584906Z","iopub.status.idle":"2025-01-02T23:03:18.585204Z","shell.execute_reply":"2025-01-02T23:03:18.585069Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation analysis for numeric features pertimbangkan untuk drop yang korelasinya rendah\ncorr_matrix = data_num.corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\nplt.title(\"Correlation Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.586193Z","iopub.status.idle":"2025-01-02T23:03:18.586632Z","shell.execute_reply":"2025-01-02T23:03:18.586440Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_cat = pd.get_dummies(data_cat,columns=cat_col)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.587533Z","iopub.status.idle":"2025-01-02T23:03:18.587954Z","shell.execute_reply":"2025-01-02T23:03:18.587766Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_cat.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.588872Z","iopub.status.idle":"2025-01-02T23:03:18.589347Z","shell.execute_reply":"2025-01-02T23:03:18.589121Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.concat([df, data_cat],axis=1)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.590355Z","iopub.status.idle":"2025-01-02T23:03:18.590677Z","shell.execute_reply":"2025-01-02T23:03:18.590521Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.591510Z","iopub.status.idle":"2025-01-02T23:03:18.591796Z","shell.execute_reply":"2025-01-02T23:03:18.591680Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(columns=cat_col,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.592649Z","iopub.status.idle":"2025-01-02T23:03:18.592927Z","shell.execute_reply":"2025-01-02T23:03:18.592815Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Normalization","metadata":{}},{"cell_type":"code","source":"num_col = list(df.select_dtypes(include='number').columns)\nnum_col.remove('type')","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.593845Z","iopub.status.idle":"2025-01-02T23:03:18.594186Z","shell.execute_reply":"2025-01-02T23:03:18.594021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_col","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.594994Z","iopub.status.idle":"2025-01-02T23:03:18.595411Z","shell.execute_reply":"2025-01-02T23:03:18.595216Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"minmax_scale = MinMaxScaler(feature_range=(0, 1))","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.596184Z","iopub.status.idle":"2025-01-02T23:03:18.596472Z","shell.execute_reply":"2025-01-02T23:03:18.596350Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalization(df,col):\n  for i in col:\n    arr = df[i]\n    arr = np.array(arr)\n    df[i] = minmax_scale.fit_transform(arr.reshape(len(arr),1))\n  return df","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.597146Z","iopub.status.idle":"2025-01-02T23:03:18.597454Z","shell.execute_reply":"2025-01-02T23:03:18.597328Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.598380Z","iopub.status.idle":"2025-01-02T23:03:18.598658Z","shell.execute_reply":"2025-01-02T23:03:18.598545Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_normalization = df.copy()\ndf_normalization = normalization(df.copy(),num_col)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.599713Z","iopub.status.idle":"2025-01-02T23:03:18.600118Z","shell.execute_reply":"2025-01-02T23:03:18.599966Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_normalization = df_normalization.drop(columns=['eth.dst'])","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.600854Z","iopub.status.idle":"2025-01-02T23:03:18.601159Z","shell.execute_reply":"2025-01-02T23:03:18.601021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_normalization.columns","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.602065Z","iopub.status.idle":"2025-01-02T23:03:18.602419Z","shell.execute_reply":"2025-01-02T23:03:18.602267Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_normalization['type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.603350Z","iopub.status.idle":"2025-01-02T23:03:18.603919Z","shell.execute_reply":"2025-01-02T23:03:18.603583Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# label\nbin_label = pd.DataFrame(df_normalization['type'])","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.604721Z","iopub.status.idle":"2025-01-02T23:03:18.605221Z","shell.execute_reply":"2025-01-02T23:03:18.605006Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bin_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.606055Z","iopub.status.idle":"2025-01-02T23:03:18.606470Z","shell.execute_reply":"2025-01-02T23:03:18.606331Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creating a dataframe with binary labels (normal,abnormal)\nbin_data = df_normalization.copy()\n\n# Menambahkan kolom 'type' dengan bin_label\nbin_data['type'] = bin_label","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.607173Z","iopub.status.idle":"2025-01-02T23:03:18.607517Z","shell.execute_reply":"2025-01-02T23:03:18.607390Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bin_data['type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.608324Z","iopub.status.idle":"2025-01-02T23:03:18.608659Z","shell.execute_reply":"2025-01-02T23:03:18.608512Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Contoh: Salin DataFrame normalisasi\nbin_data = df_normalization.copy()\n\n# Pastikan bin_label adalah Series atau list dengan panjang yang sesuai\nif isinstance(bin_label, (list, np.ndarray)):\n    bin_label = pd.Series(bin_label)\n\n# Cek apakah panjang bin_label sama dengan bin_data\nif len(bin_data) == len(bin_label):\n    bin_data['type'] = bin_label\nelse:\n    print(\"Panjang bin_label tidak sesuai dengan jumlah baris bin_data.\")\n\n# Menampilkan beberapa baris untuk memeriksa\nprint(bin_data.head())\nprint(bin_data.columns)  # Memeriksa semua kolom dalam bin_data\n","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.609726Z","iopub.status.idle":"2025-01-02T23:03:18.610065Z","shell.execute_reply":"2025-01-02T23:03:18.609938Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bin_label = bin_label.replace({1: 'normal', 0: 'MitM'})","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.611087Z","iopub.status.idle":"2025-01-02T23:03:18.611698Z","shell.execute_reply":"2025-01-02T23:03:18.611511Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bin_label.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.612893Z","iopub.status.idle":"2025-01-02T23:03:18.613346Z","shell.execute_reply":"2025-01-02T23:03:18.613120Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# label encoding (0,1) binary labels\nle1 = preprocessing.LabelEncoder()\nenc_label = bin_label.apply(le1.fit_transform)\nbin_data['type'] = enc_label","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.614210Z","iopub.status.idle":"2025-01-02T23:03:18.614611Z","shell.execute_reply":"2025-01-02T23:03:18.614411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le1.classes_","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.615437Z","iopub.status.idle":"2025-01-02T23:03:18.615776Z","shell.execute_reply":"2025-01-02T23:03:18.615618Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bin_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.616982Z","iopub.status.idle":"2025-01-02T23:03:18.617392Z","shell.execute_reply":"2025-01-02T23:03:18.617202Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.pie(df_raw.type.value_counts(),labels=['normal','MitM'],autopct='%0.2f%%')\nplt.title(\"Pie chart distribution of normal and abnormal labels\",fontsize=16)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.618549Z","iopub.status.idle":"2025-01-02T23:03:18.618952Z","shell.execute_reply":"2025-01-02T23:03:18.618762Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Plot the distribution of the labels\nplt.figure(figsize=(6, 4))\nsns.countplot(x='type', data=df_raw)\nplt.title('Distribution of Labels')\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.619642Z","iopub.status.idle":"2025-01-02T23:03:18.619951Z","shell.execute_reply":"2025-01-02T23:03:18.619831Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SMOTE","metadata":{}},{"cell_type":"markdown","source":"Dikarenakan jauhnya perbedaan pada distribusi label, kita akan menyamaratakan labelnya menggunakan metode SMOTE","metadata":{}},{"cell_type":"code","source":"# 1. Mengimpor Modul yang Diperlukan\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pickle\nfrom os import path\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.620941Z","iopub.status.idle":"2025-01-02T23:03:18.621324Z","shell.execute_reply":"2025-01-02T23:03:18.621192Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bin_data.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.622118Z","iopub.status.idle":"2025-01-02T23:03:18.622447Z","shell.execute_reply":"2025-01-02T23:03:18.622331Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = bin_data.drop(columns=['type'],axis=1)\ny = bin_data['type']","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.623246Z","iopub.status.idle":"2025-01-02T23:03:18.623626Z","shell.execute_reply":"2025-01-02T23:03:18.623440Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # changing attack labels into two categories 'normal' and 'mitm'\n# y_bin = y_bin.replace({1: 'normal', 0: 'MitM'})","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.624884Z","iopub.status.idle":"2025-01-02T23:03:18.625285Z","shell.execute_reply":"2025-01-02T23:03:18.625108Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X, y, test_size=0.2, random_state=50)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.626231Z","iopub.status.idle":"2025-01-02T23:03:18.626620Z","shell.execute_reply":"2025-01-02T23:03:18.626435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test_bin","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.627698Z","iopub.status.idle":"2025-01-02T23:03:18.628044Z","shell.execute_reply":"2025-01-02T23:03:18.627916Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom collections import Counter\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.628836Z","iopub.status.idle":"2025-01-02T23:03:18.629246Z","shell.execute_reply":"2025-01-02T23:03:18.629038Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.630288Z","iopub.status.idle":"2025-01-02T23:03:18.630670Z","shell.execute_reply":"2025-01-02T23:03:18.630477Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_bin","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.631697Z","iopub.status.idle":"2025-01-02T23:03:18.632044Z","shell.execute_reply":"2025-01-02T23:03:18.631893Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X_train_bin, y_train_bin)\n\nfrom collections import Counter\nprint(f\"Distribusi kelas sebelum SMOTE: {Counter(y_train_bin)}\")\nprint(f\"Distribusi kelas setelah SMOTE: {Counter(y_resampled)}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.633107Z","iopub.status.idle":"2025-01-02T23:03:18.633528Z","shell.execute_reply":"2025-01-02T23:03:18.633379Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_resampled","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.634431Z","iopub.status.idle":"2025-01-02T23:03:18.634837Z","shell.execute_reply":"2025-01-02T23:03:18.634637Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_resampled.value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.635809Z","iopub.status.idle":"2025-01-02T23:03:18.636229Z","shell.execute_reply":"2025-01-02T23:03:18.636003Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.pie(y_resampled.value_counts(),labels=['Normal','MitM'],autopct='%0.2f%%')\nplt.title(\"Pie chart distribution of normal and abnormal labels\",fontsize=16)\nplt.legend()\n# plt.savefig('/content/gdrive/My Drive/ASDOS/template/Topik1_Studi Transformer-Based Sequence Modelling untuk Deteksi Ransomware Melalui Analisis Trafik Jaringan yang Mengenkripsi Secara Tiba-tiba/plot/Pie_chart_binary2.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.637254Z","iopub.status.idle":"2025-01-02T23:03:18.637624Z","shell.execute_reply":"2025-01-02T23:03:18.637442Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bin_data","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.638633Z","iopub.status.idle":"2025-01-02T23:03:18.638997Z","shell.execute_reply":"2025-01-02T23:03:18.638839Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import Transformer","metadata":{}},{"cell_type":"code","source":"!pip install transformers tensorflow","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.639890Z","iopub.status.idle":"2025-01-02T23:03:18.640273Z","shell.execute_reply":"2025-01-02T23:03:18.640097Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformer Encoder","metadata":{}},{"cell_type":"code","source":"le1.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:03:18.641339Z","iopub.status.idle":"2025-01-02T23:03:18.641648Z","shell.execute_reply":"2025-01-02T23:03:18.641524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = le1.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:03:18.642961Z","iopub.status.idle":"2025-01-02T23:03:18.643384Z","shell.execute_reply":"2025-01-02T23:03:18.643196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le1.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:03:18.644287Z","iopub.status.idle":"2025-01-02T23:03:18.644682Z","shell.execute_reply":"2025-01-02T23:03:18.644501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and Validation Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1. Preprocessing: Label Encoding dan Normalization\n# le = LabelEncoder()\n# y_bin = le.fit_transform(combined_df['type'].values)  # Encode labels\nclass_names = le1.classes_  # Save the original class names\n\n# Normalize feature data\nscaler = StandardScaler()\nX_bin = scaler.fit_transform(combined_df.drop(columns=['type']).values)\ny_bin = combined_df['type'].values\n\n# 2. Define Transformer Model\nclass TransformerModel(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(TransformerModel, self).__init__()\n        self.embedding = nn.Linear(input_dim, 64)\n        self.transformer_encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=64, nhead=2, batch_first=True),\n            num_layers=2\n        )\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.unsqueeze(1)  # Add sequence dimension (batch_size, seq_length, feature_dim)\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=1)  # Average pooling\n        return self.fc(x)\n\n# 3. KFold Cross-Validation\nkf = KFold(n_splits=10, shuffle=True, random_state=50)\nall_accuracy, all_f1_scores, all_recall_scores = [], [], []\nconf_matrix_list = []\n\nfor fold, (train_index, val_index) in enumerate(kf.split(X_bin)):\n    print(f'Fold {fold + 1}')\n\n    # Split data\n    X_train, X_val = X_bin[train_index], X_bin[val_index]\n    y_train, y_val = y_bin[train_index], y_bin[val_index]\n\n    # Convert to PyTorch tensors\n    X_train_tensor = torch.FloatTensor(X_train)\n    y_train_tensor = torch.LongTensor(y_train)\n    X_val_tensor = torch.FloatTensor(X_val)\n    y_val_tensor = torch.LongTensor(y_val)\n\n    # Create DataLoader\n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\n    # Initialize the model\n    model = TransformerModel(input_dim=X_train.shape[1], num_classes=len(class_names))\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\n    # Early stopping setup\n    best_accuracy = 0\n    patience, trigger_times = 5, 0\n\n    # Lists for storing loss and accuracy values for each epoch\n    train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []\n    num_epochs = 50\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n        \n        # Training loop\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            \n            # Calculate training accuracy\n            _, predicted = torch.max(outputs, 1)\n            correct_train += (predicted == labels).sum().item()\n            total_train += labels.size(0)\n        \n        scheduler.step()\n        \n        # Calculate average training loss and accuracy for this epoch\n        avg_train_loss = running_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        train_accuracy = correct_train / total_train\n        train_accuracies.append(train_accuracy)\n\n        # Validate the model\n        model.eval()\n        val_running_loss = 0.0\n        with torch.no_grad():\n            y_pred_probs = model(X_val_tensor)\n            val_loss = criterion(y_pred_probs, y_val_tensor).item()\n            val_running_loss += val_loss\n            _, y_pred = torch.max(y_pred_probs, 1)\n        \n        # Append validation loss and accuracy\n        val_losses.append(val_running_loss)\n        accuracy = accuracy_score(y_val, y_pred.numpy())\n        val_accuracies.append(accuracy)\n\n        # Save the best model\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            torch.save(model.state_dict(), f'model_fold_{fold + 1}.pt')\n            trigger_times = 0\n        else:\n            trigger_times += 1\n\n        if trigger_times >= patience:\n            print(f'Early stopping triggered at epoch {epoch + 1}')\n            break\n\n    # Metrics calculation\n    conf_matrix = confusion_matrix(y_val, y_pred.numpy())\n    conf_matrix_list.append(conf_matrix)\n    all_accuracy.append(accuracy)\n\n    f1 = f1_score(y_val, y_pred.numpy(), average='weighted')\n    all_f1_scores.append(f1)\n\n    recall = recall_score(y_val, y_pred.numpy(), average='weighted')\n    all_recall_scores.append(recall)\n\n    # Print results for the current fold\n    print(f'Accuracy for fold {fold + 1}: {accuracy * 100:.2f}%')\n    print(f'Recall for fold {fold + 1}: {recall:.4f}')\n    print(f'F1 Score for fold {fold + 1}: {f1:.4f}')\n    cls_report = classification_report(y_val, y_pred.numpy(), target_names=le1.classes_)\n    print(cls_report)\n\n    # Plot loss and accuracy for the current fold\n    plt.figure(figsize=(14, 10))\n    \n    # Plot for training and validation loss\n    plt.subplot(2, 1, 1)\n    plt.plot(train_losses, label=\"Training Loss\")\n    plt.plot(val_losses, label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(f'Loss for Fold {fold + 1}')\n    plt.legend()\n    \n    # Plot for training and validation accuracy\n    plt.subplot(2, 1, 2)\n    plt.plot(train_accuracies, label=\"Training Accuracy\")\n    plt.plot(val_accuracies, label=\"Validation Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(f'Accuracy for Fold {fold + 1}')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n    # Plot confusion matrix for the current fold\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(conf_matrix, annot=True, fmt='.0f', cmap='Blues', cbar=False,\n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title(f'Confusion Matrix for Fold {fold + 1}')\n    plt.show()\n\n# 4. Average Metrics Across All Folds\nprint(f'Average Accuracy: {np.mean(all_accuracy) * 100:.2f}%')\nprint(f'Average Recall: {np.mean(all_recall_scores):.4f}')\nprint(f'Average F1 Score: {np.mean(all_f1_scores):.4f}')\n\n# Plot accuracy, recall, and F1 score across all folds\nfolds = np.arange(1, len(all_accuracy) + 1)\n\n# Plot Accuracy per fold\nplt.figure(figsize=(10, 6))\nplt.plot(folds, np.array(all_accuracy) * 100, marker='o', label='Accuracy (%)')\nplt.xlabel('Fold')\nplt.ylabel('Accuracy (%)')\nplt.title('Accuracy per Fold')\nplt.xticks(folds)  # Ensure x-axis corresponds to fold numbers\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot Recall per fold\nplt.figure(figsize=(10, 6))\nplt.plot(folds, all_recall_scores, marker='o', label='Recall')\nplt.xlabel('Fold')\nplt.ylabel('Recall')\nplt.title('Recall per Fold')\nplt.xticks(folds)  # Ensure x-axis corresponds to fold numbers\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# # Plot F1 Score per fold\n# plt.figure(figsize=(10, 6))\n# plt.plot(folds, all_f1_scores, marker='o', label='F1 Score')\n# plt.xlabel('Fold')\n# plt.ylabel('F1 Score')\n# plt.title('F1 Score per Fold')\n# plt.xticks(folds)  # Ensure x-axis corresponds to fold numbers\n# plt.legend()\n# plt.grid(True)\n# plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-01-02T23:03:18.645685Z","iopub.status.idle":"2025-01-02T23:03:18.646081Z","shell.execute_reply":"2025-01-02T23:03:18.645894Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Data","metadata":{}},{"cell_type":"code","source":"# 5. Testing\n# Assume `X_test` dan `y_test` adalah dataset testing yang sudah dipersiapkan sebelumnya\n# X_test adalah data fitur dan y_test adalah label yang sesuai\n\n# Normalize test data using the same scaler\nX_test = scaler.transform(X_test)\n\n# Convert to PyTorch tensor\nX_test_tensor = torch.FloatTensor(X_test)\ny_test_tensor = torch.LongTensor(y_test.values)\n\n# Create DataLoader for the test dataset\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Initialize the model (load the best model from the fold with highest accuracy)\nbest_fold = np.argmax(all_accuracy)  # Get the fold with the highest accuracy\nmodel_path = f'model_fold_{best_fold + 1}.pt'\nmodel.load_state_dict(torch.load(model_path))\n\n# Put model in evaluation mode\nmodel.eval()\n\n# Testing loop\ntest_running_loss = 0.0\ncorrect_test = 0\ntotal_test = 0\ny_test_pred = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_running_loss += loss.item()\n        \n        # Calculate test accuracy\n        _, predicted = torch.max(outputs, 1)\n        correct_test += (predicted == labels).sum().item()\n        total_test += labels.size(0)\n        \n        y_test_pred.extend(predicted.numpy())\n\n# Calculate average test loss and accuracy\navg_test_loss = test_running_loss / len(test_loader)\ntest_accuracy = correct_test / total_test\n\n# Print test results\nprint(f'Test Accuracy: {test_accuracy * 100:.2f}%')\nprint(f'Test Loss: {avg_test_loss:.4f}')\n\n# Classification report on test set\nprint('Test Classification Report:')\nprint(classification_report(y_test, y_test_pred, target_names=class_names))\n\n# Confusion matrix for the test set\nconf_matrix_test = confusion_matrix(y_test, y_test_pred)\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix_test, annot=True, fmt='.0f', cmap='Blues', cbar=False,\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix for Test Set')\nplt.show()\n\n# Optionally, plot metrics for test data similar to training/validation\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:03:18.647089Z","iopub.status.idle":"2025-01-02T23:03:18.647497Z","shell.execute_reply":"2025-01-02T23:03:18.647338Z"}},"outputs":[],"execution_count":null}]}